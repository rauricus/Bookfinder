{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbdfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NOTEBOOKS_DIR = os.getcwd()\n",
    "HOME_DIR = os.path.dirname(NOTEBOOKS_DIR)\n",
    "\n",
    "def get_next_directory(base_path=\"output/predict\"):\n",
    "    # Check if the base directory exists\n",
    "    if not os.path.exists(base_path):\n",
    "        return base_path\n",
    "    else:\n",
    "        # Find the next available numbered directory\n",
    "        i = 2\n",
    "        while os.path.exists(f\"{base_path}{i}\"):\n",
    "            i += 1\n",
    "        return f\"{base_path}{i}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f738e69-8ca5-46a7-8a8c-abeff29fa2ce",
   "metadata": {},
   "source": [
    "# Perform object detection\n",
    "\n",
    "Perform the inference with the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81faa6e6-cf3a-433e-a847-229f1c4bf69f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/example-files/books/books_00005.png: 480x640 87.4ms\n",
      "Speed: 1.9ms preprocess, 87.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO(\"yolo11s.pt\", )  # load an official model\n",
    "# model = YOLO(\"yolo11s-seg.pt\")  # load an official model (instance segmentation)\n",
    "model = YOLO(HOME_DIR+\"/runs/obb/train/weights/best.pt\")  # load an official model (Oriented Bounding Boxes Object Detection)\n",
    "#model = YOLO(HOME_DIR+\"/runs/segment/train/weights/best.pt\")  # load my custom model\n",
    "\n",
    "# source = 'https://ultralytics.com/images/bus.jpg'\n",
    "# source = HOME_DIR+'/example-files/IMG_3688.png'\n",
    "# source = HOME_DIR+'/example-files/books'\n",
    "# source = HOME_DIR+'/example-files/books.mov'\n",
    "source = HOME_DIR+'/example-files/books/books_00005.png'\n",
    "\n",
    "# Predict with the model\n",
    "results = model.predict(source, conf=0.5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d223f",
   "metadata": {},
   "source": [
    "# Adjust images (OBB only)\n",
    "\n",
    "From: https://github.com/ultralytics/ultralytics/issues/9344\n",
    "\n",
    "Switching to an OBB (oriented bounding box) model means you'll be working with rotated bounding boxes. The .boxes attribute for an OBB model will contain the center coordinates, width, height, and angle in radians.\n",
    "\n",
    "I took the following crop_rect function from here, as it also rotates the image: https://github.com/ultralytics/ultralytics/issues/13650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def crop_rect(img, rect, interpolation=cv2.INTER_CUBIC):\n",
    "    \"\"\"\n",
    "    Extracts and rectifies a rotated bounding box from an image.\n",
    "\n",
    "    This function takes an image and an oriented bounding box (OBB), rotates the \n",
    "    image such that the bounding box becomes axis-aligned (rectangular), and then \n",
    "    crops the bounding box area.\n",
    "\n",
    "    Args:\n",
    "        img (numpy.ndarray): The input image from which the bounding box is extracted.\n",
    "        rect (tuple): The oriented bounding box parameters.\n",
    "                     - rect[0]: Center coordinates of the bounding box (x, y).\n",
    "                     - rect[1]: Size of the bounding box (width, height).\n",
    "                     - rect[2]: Rotation angle of the bounding box (in degrees).\n",
    "        interpolation (int, optional): Interpolation method used when rotating the image.\n",
    "                                       Defaults to cv2.INTER_CUBIC.\n",
    "\n",
    "    Returns:\n",
    "        cropped_image (numpy.ndarray): The cropped rectangle region from the rotated image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Process:\n",
    "    #    1. Extracts the center, size, and angle of the bounding box.\n",
    "    #    2. Computes a rotation matrix to align the bounding box with the image axes.\n",
    "    #    3. Rotates the image based on the calculated rotation matrix.\n",
    "    #    4. Crops the now axis-aligned bounding box from the rotated image.\n",
    "\n",
    "\n",
    "    # get the parameter of the small rectangle\n",
    "    center, size, angle = rect[0], rect[1], rect[2]\n",
    "    center, size = tuple(map(int, center)), tuple(map(int, size))\n",
    "\n",
    "    # get row and col num in img\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "    # calculate the rotation matrix\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "    # rotate the original image\n",
    "    img_rot = cv2.warpAffine(img, M, (width, height), flags=interpolation)\n",
    "\n",
    "    # now rotated rectangle becomes vertical, and we crop it\n",
    "    img_crop = cv2.getRectSubPix(img_rot, size, center)\n",
    "\n",
    "    return img_crop\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def prepare_for_ocr(img):\n",
    "    \"\"\"\n",
    "    Processes a cropped rectangle for OCR detection by ensuring the image is wider than tall\n",
    "    and generating both the original (or rotated) and a 180-degree rotated variant.\n",
    "    \n",
    "    Args:\n",
    "        img (numpy.ndarray): The cropped rectangle image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (processed_img, rotated_180_img)\n",
    "               - processed_img: Image oriented to be wider than tall.\n",
    "               - rotated_180_img: 180-degree rotated version of `processed_img`.\n",
    "    \"\"\"\n",
    "    # Get image dimensions\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Rotate 90 degrees clockwise if the image is taller than it is wide\n",
    "    if height > width:\n",
    "        img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    # Generate the 180-degree rotated image\n",
    "    rotated_180_img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "\n",
    "    return img, rotated_180_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bff58f",
   "metadata": {},
   "source": [
    "# Save results, rotate and crop images (OBB only)\n",
    "\n",
    "The main code is again from https://github.com/ultralytics/ultralytics/issues/13650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'book', 'class': 0, 'confidence': 0.92829, 'box': {'x1': 2138.47437, 'y1': 2193.1355, 'x2': 2474.677, 'y2': 2211.39282, 'x3': 2559.83325, 'y3': 643.29034, 'x4': 2223.63062, 'y4': 625.03278}}, {'name': 'book', 'class': 0, 'confidence': 0.9155, 'box': {'x1': 2761.04785, 'y1': 2158.79468, 'x2': 2935.44092, 'y2': 2165.02563, 'x3': 2985.83789, 'y3': 754.52069, 'x4': 2811.44482, 'y4': 748.28961}}, {'name': 'book', 'class': 0, 'confidence': 0.91296, 'box': {'x1': 2932.27344, 'y1': 2170.69287, 'x2': 3104.52686, 'y2': 2176.56885, 'x3': 3153.72607, 'y3': 734.31586, 'x4': 2981.47266, 'y4': 728.43988}}, {'name': 'book', 'class': 0, 'confidence': 0.90544, 'box': {'x1': 2501.48193, 'y1': 2174.44922, 'x2': 2753.79492, 'y2': 2187.65234, 'x3': 2831.42773, 'y3': 704.11011, 'x4': 2579.11475, 'y4': 690.90674}}, {'name': 'book', 'class': 0, 'confidence': 0.8734, 'box': {'x1': 3395.00659, 'y1': 2191.71704, 'x2': 3565.38354, 'y2': 2203.33618, 'x3': 3671.73657, 'y3': 643.80688, 'x4': 3501.35962, 'y4': 632.18787}}, {'name': 'book', 'class': 0, 'confidence': 0.84513, 'box': {'x1': 1702.9198, 'y1': 2186.43945, 'x2': 1848.88708, 'y2': 2191.30078, 'x3': 1898.17151, 'y3': 711.41455, 'x4': 1752.20422, 'y4': 706.55347}}, {'name': 'book', 'class': 0, 'confidence': 0.82285, 'box': {'x1': 1574.64612, 'y1': 2192.63843, 'x2': 1693.94666, 'y2': 2194.91626, 'x3': 1723.3241, 'y3': 656.21393, 'x4': 1604.02356, 'y4': 653.93622}}, {'name': 'book', 'class': 0, 'confidence': 0.80939, 'box': {'x1': 3053.9375, 'y1': 2170.57983, 'x2': 3401.18262, 'y2': 2199.17896, 'x3': 3529.7876, 'y3': 637.69336, 'x4': 3182.54248, 'y4': 609.09399}}, {'name': 'book', 'class': 0, 'confidence': 0.79645, 'box': {'x1': 1333.94604, 'y1': 2134.271, 'x2': 1490.21387, 'y2': 2132.9292, 'x3': 1479.5564, 'y3': 891.95288, 'x4': 1323.28857, 'y4': 893.29492}}, {'name': 'book', 'class': 0, 'confidence': 0.77945, 'box': {'x1': 1473.78943, 'y1': 2192.73584, 'x2': 1574.33899, 'y2': 2193.96631, 'x3': 1591.52258, 'y3': 789.7038, 'x4': 1490.97302, 'y4': 788.47345}}, {'name': 'book', 'class': 0, 'confidence': 0.74262, 'box': {'x1': 1157.23877, 'y1': 2151.72217, 'x2': 1272.46558, 'y2': 2148.1875, 'x3': 1233.41797, 'y3': 875.24438, 'x4': 1118.19116, 'y4': 878.77893}}, {'name': 'book', 'class': 0, 'confidence': 0.58797, 'box': {'x1': 1902.82434, 'y1': 2198.26636, 'x2': 2002.6969, 'y2': 2199.96509, 'x3': 2028.70667, 'y3': 670.87231, 'x4': 1928.83411, 'y4': 669.17346}}, {'name': 'book', 'class': 0, 'confidence': 0.56269, 'box': {'x1': 1710.62183, 'y1': 3022.11987, 'x2': 1736.32983, 'y2': 2637.97388, 'x3': 371.00494, 'y3': 2546.60278, 'x4': 345.29694, 'y4': 2930.74878}}]\n"
     ]
    }
   ],
   "source": [
    "# Create the output directory, if needed\n",
    "OUTPUT_DIR = get_next_directory(os.path.join(HOME_DIR, \"output/predict\"))\n",
    "os.makedirs(OUTPUT_DIR+\"/book\", exist_ok=True)\n",
    "\n",
    "# Get only filename with no directories and no extension\n",
    "filename = os.path.splitext(os.path.basename(source))[0]\n",
    "\n",
    "# Process results\n",
    "with open(OUTPUT_DIR+\"/results.json\", \"w\") as text_file:\n",
    "    for result in results:\n",
    "        \n",
    "        if (len(result) > 0):\n",
    "            result.show()\n",
    "\n",
    "            print(result.to_json(), file=text_file)\n",
    "\n",
    "            for idx, obb in enumerate(result.obb.xyxyxyxy):\n",
    "                points = obb.cpu().numpy().reshape((-1, 1, 2)).astype(int)\n",
    "                rect = cv2.minAreaRect(points)\n",
    "\n",
    "                # Rotate the image slightly so that it aligns with the axes.\n",
    "                img_cropped = crop_rect(result.orig_img, rect)\n",
    "\n",
    "                # Ensure the image is wider than tall and also return a variant rotated by 180 degrees.\n",
    "                img, img_rotated_180 = prepare_for_ocr(img_cropped)\n",
    "\n",
    "                cv2.imwrite(os.path.join(OUTPUT_DIR, \"book\", f\"{filename}_{idx}.jpg\"), img)\n",
    "                cv2.imwrite(os.path.join(OUTPUT_DIR, \"book\", f\"{filename}_rotated-180_{idx}.jpg\"), img_rotated_180)\n",
    "\n",
    "            result.save_txt(OUTPUT_DIR+\"/results.txt\", save_conf=True)\n",
    "\n",
    "            print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21dee09-5421-4abd-a558-a128d892828b",
   "metadata": {},
   "source": [
    "# Save results and cropped images\n",
    "\n",
    "Saves a JSON file with all results (includes class and confidence). Saves images for each bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25064ea0-37f0-4da0-8fa2-122af0e56271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory, if needed\n",
    "OUTPUT_DIR = get_next_directory(os.path.join(HOME_DIR, \"output/predict\"))\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Process results\n",
    "with open(OUTPUT_DIR+\"/results.json\", \"w\") as text_file:\n",
    "    for result in results:\n",
    "        \n",
    "        if (len(result) > 0):\n",
    "            result.show()\n",
    "\n",
    "            print(result.to_json(), file=text_file)\n",
    "            result.save_crop(OUTPUT_DIR, \"image\")\n",
    "            result.save_txt(OUTPUT_DIR+\"/results.txt\", save_conf=True)\n",
    "\n",
    "            print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470ef06",
   "metadata": {},
   "source": [
    "# Perform OCR on each book image found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "def ocr_onImage(img_path):\n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    # --- Perform OCR using EasyOCR\n",
    "    #reader = easyocr.Reader(['de'])  # Choose language\n",
    "    #ocr_text = reader.readtext(cropped_image, rotation_info=[90,180,270], paragraph=True, width_ths=0.7, detail=0)\n",
    "\n",
    "    # --- Perform OCR using Tesseract\n",
    "\n",
    "    # Do some image processing first.\n",
    "    #img = grayscale(rotated_image)\n",
    "    #img = thresholding(img)\n",
    "    #img = denoise(img)\n",
    "\n",
    "    return ocr_core(image)\n",
    "\n",
    "def ocr_core(img):\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "# get grayscale image\n",
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def denoise(image):\n",
    "    return cv2.medianBlur(image, 5)\n",
    "\n",
    "# thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5f7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 0 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_0.jpg\n",
      "->  FUR VERNUNFT,\n",
      "WISSENSCHAFT,\n",
      "\n",
      "HUMANISMUS\n",
      "UND FORTSCHRITE\n",
      "\n",
      "\n",
      "Book 1 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_1.jpg\n",
      "->  HANSI\n",
      "\n",
      "\n",
      "Book 2 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_2.jpg\n",
      "->  RONJA VON RONNE | ENDE IN SICHT\n",
      "\n",
      "Book 3 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_3.jpg\n",
      "->  Jaron Lanier Wem gehdrt die Zukunft?\n",
      "eo a - - ea\n",
      "\n",
      "\n",
      "Book 4 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_4.jpg\n",
      "->  |e ANGELIKA A WALDIS « ICH KOMME Mit\n",
      "\n",
      "FOOT et A\n",
      "\n",
      "Book 5 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_5.jpg\n",
      "->  | ® SATOSHI YAGISAWA DIE TAGE IN DER BUCHHANDLUNG MORISAKI\n",
      "\n",
      "Book 6 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_6.jpg\n",
      "->  ) SLLAANVHLVNOfL  somaaaxe apnry8u07 105 as9nB oy pue NOSIMYVH NHOL\n",
      "\n",
      "‘eg\n",
      "\n",
      "Book 7 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_7.jpg\n",
      "->  \n",
      "Book 8 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_8.jpg\n",
      "->  sYILUII8 sep a1g Uaqey dIM SPosyITH “I\n",
      "\n",
      "2ANASH  y nyaanyl SIOONVYE\n",
      "\n",
      "\n",
      "Book 9 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_9.jpg\n",
      "->  |. Nordis SKANDINAVIEN 2022\n",
      "\n",
      "Book 10 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_10.jpg\n",
      "->  uassnul ujaZaI aSt1y JOp Uy ove SUA — sunuuoly, VASHIVYL 13INVO 4a3ydeqoog\n",
      "\n",
      "\n",
      "Book 11 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_11.jpg\n",
      "->  \n",
      "Book 12 found\n",
      "Image path: /Users/andreas/Documents/Projekte/Objekterkennung.yolo11/output/predict/book/books_00005_crop_12.jpg\n",
      "->  zurtick 17 tO OM BS rer\n",
      "Was sich Ae Menschen von\n",
      "dem verspracne™, kommt\n",
      "\n",
      "von soasttm Radkau\n",
      "\n",
      "«wenn Fra\n",
      "alles stillir= was ist am\n",
      "74. Jun! 1991 pass\n",
      "\n",
      "Ke\n",
      "aiser Jer FIBNZOSON\n",
      "\n",
      "o\n",
      "44\n",
      "\n",
      "jert2\n",
      "\n",
      "Vo\n",
      "pa a«E/p P- ? 5 i\n",
      "Vz eee Se as th» Die Holle F rauenstreik?\n",
      "FG Zamaysk/ pee pbai eve Eine Geschichte Jer, u will, scent\n",
      "— ie aperfektesten rotalitaren\n",
      "\n",
      "Foltersystems”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "#import easyocr\n",
    "import pytesseract\n",
    "\n",
    "# --- Needs tesseract on the path. I've installed it via homebrew.\n",
    "\n",
    "# Get only filename with no directories and no extension\n",
    "filename = os.path.splitext(os.path.basename(source))[0]\n",
    "\n",
    "for result in results:\n",
    "\n",
    "    if (len(result) > 0):\n",
    "        # for object detection and instance separation\n",
    "        # i=1\n",
    "\n",
    "        # for OBB\n",
    "        i=0\n",
    "\n",
    "        for detection in result.summary(): \n",
    "            if (detection['name'] == 'book'):\n",
    "                print(f\"Book {i} found\")\n",
    "\n",
    "                # for object detection and instance separation\n",
    "                # image_filename = f\"image{i}.jpg\" if i>1 else 'image.jpg'\n",
    "                # image_path = OUTPUT_DIR + '/book/' + image_filename\n",
    "                \n",
    "                # for OBB\n",
    "                # Perform OCR on all (both) image variants.\n",
    "                image_variants = [\n",
    "                    f\"{filename}_{i}.jpg\",  # Original image\n",
    "                    f\"{filename}_rotated-180_{i}.jpg\"  # 180-degree rotated image\n",
    "                ]\n",
    "\n",
    "                # Iterate over each variant, process the OCR, and print the result\n",
    "                for variant_filename in image_variants:\n",
    "                    img_path = os.path.join(OUTPUT_DIR, \"book\", variant_filename)\n",
    "                    ocr_text = ocr_onImage(img_path)\n",
    "                    print(f\"{img_path} -> {ocr_text}\")\n",
    "\n",
    "                i += 1\n",
    "            else:\n",
    "                print(\"Skipping\", detection['name'], '...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
